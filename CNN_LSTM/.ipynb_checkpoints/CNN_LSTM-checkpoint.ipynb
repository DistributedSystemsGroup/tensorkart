{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.util import nest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 10 # length of BPTT\n",
    "BATCH_SIZE = 4 # number of sequence fragments used in a single optimization step\n",
    "LEFT_CONTEXT = 5 # frames from the past that we append to the left of our input sequence, 3D convolution with \"VALID\" padding \"eats\" frames from the left\n",
    "\n",
    "# input image parameters\n",
    "HEIGHT = 480\n",
    "WIDTH = 640\n",
    "CHANNELS = 3 # RGB\n",
    "\n",
    "# parameters of the LSTM that keeps the model state\n",
    "RNN_SIZE = 32\n",
    "RNN_PROJ = 32\n",
    "\n",
    "CSV_HEADER = \"img_path,x_steering,y_steering,throttle,A,B\".split(\",\")\n",
    "# OUTPUTS = [CSV_HEADER[1], CSV_HEADER[3]] # x_steering,throttle\n",
    "OUTPUTS = [CSV_HEADER[1]] # x_steering\n",
    "OUTPUT_DIM = len(OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS FOR READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv(dir_):\n",
    "    lines = []\n",
    "    for filename in os.listdir(dir_):\n",
    "        filename =  dir_ + '/' + filename + '/data.csv'\n",
    "        with open(filename, 'r') as f:\n",
    "            ls = [ln.strip().split(\",\")[0:2] for ln in f.readlines()] # filename and steering\n",
    "            ls = list(map(lambda x: (dir_ + '/' + x[0][8:], np.float32(x[1])), ls)) # remove \"samples/\"\n",
    "            for i in range(len(ls)):\n",
    "                lines.append(ls[i])\n",
    "    return lines\n",
    "tot = 10\n",
    "def process_csv(dir_, val=5):\n",
    "    sum_f = np.float128([0.0] * OUTPUT_DIM)\n",
    "    sum_sq_f = np.float128([0.0] * OUTPUT_DIM)\n",
    "    lines = read_csv(dir_)\n",
    "    # leave val% for validation\n",
    "    train_seq = []\n",
    "    valid_seq = []\n",
    "    cnt = 0\n",
    "    for ln in lines:\n",
    "        if cnt < SEQ_LEN * BATCH_SIZE * (tot - val): \n",
    "        \n",
    "            train_seq.append(ln)\n",
    "            sum_f += np.float128(ln[1])\n",
    "            sum_sq_f += np.float128(ln[1]) * np.float128(ln[1])\n",
    "        else:\n",
    "            valid_seq.append(ln)\n",
    "        cnt += 1\n",
    "        cnt %= SEQ_LEN * BATCH_SIZE * tot\n",
    "    mean = sum_f / len(train_seq)\n",
    "    var = sum_sq_f / len(train_seq) - mean * mean\n",
    "    std = np.sqrt(var)\n",
    "    print(\"Training samples:\", len(train_seq), \"Validation samples:\", len(valid_seq))\n",
    "    print(\"Mean:\", mean, \"Standard deviation:\", std) # we will need these statistics to normalize the outputs (and ground truth inputs)\n",
    "    return (train_seq, valid_seq), (mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET TRAIN, VALIDATION, TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 960 Validation samples: 195\n",
      "Mean: [-0.062043826] Standard deviation: [ 0.6204935]\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../samples/training\"\n",
    "test_dir = \"../samples/test\"\n",
    "(train_seq, valid_seq), (mean, std) = process_csv(train_dir, val=2) \n",
    "test_seq = read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../samples/training/mario1/img_13.png'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, sequence, seq_len, batch_size):\n",
    "        self.sequence = sequence # train, valid or test sequence\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        num_batches = 1 + int((len(sequence) - 1) / batch_size) # how many batches we have, split the data in `BATCH_SIZE` chunks, the last might be smaller\n",
    "        self.indices = [(i*num_batches) % len(sequence) for i in range(batch_size)] # `BATCH_SIZE` indices for beginning of batches\n",
    "        \n",
    "    def next(self):\n",
    "        while True:\n",
    "            output = []\n",
    "            for i in range(self.batch_size):\n",
    "                idx = self.indices[i]\n",
    "                left_pad = self.sequence[idx - LEFT_CONTEXT:idx]\n",
    "                if len(left_pad) < LEFT_CONTEXT:\n",
    "                    left_pad = [self.sequence[0]] * (LEFT_CONTEXT - len(left_pad)) + left_pad\n",
    "                assert len(left_pad) == LEFT_CONTEXT\n",
    "                leftover = len(self.sequence) - idx\n",
    "                if leftover >= self.seq_len:\n",
    "                    result = self.sequence[idx:idx + self.seq_len]\n",
    "                else:\n",
    "                    result = self.sequence[idx:] + self.sequence[:self.seq_len - leftover]\n",
    "                assert len(result) == self.seq_len\n",
    "                self.indices[i] = (idx + self.seq_len) % len(self.sequence)\n",
    "                images, targets = zip(*result)\n",
    "                images_left_pad, _ = zip(*left_pad)\n",
    "                output.append((np.stack(images_left_pad + images), np.stack(targets)))\n",
    "            output = zip(*output)\n",
    "            output[0] = np.stack(output[0]) # batch_size x (LEFT_CONTEXT + seq_len)\n",
    "            output[1] = np.stack(output[1]) # batch_size x seq_len x OUTPUT_DIM\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_norm = lambda x: tf.contrib.layers.layer_norm(inputs=x, center=True, scale=True, activation_fn=None, trainable=True)\n",
    "\n",
    "def get_optimizer(loss, lrate):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lrate)\n",
    "    gradvars = optimizer.compute_gradients(loss)\n",
    "    gradients, v = zip(*gradvars)\n",
    "    print([x.name for x in v])\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 15.0)\n",
    "    return optimizer.apply_gradients(zip(gradients, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original\n",
    "def apply_vision_simple(image, keep_prob, batch_size, seq_len, scope=None, reuse=None):\n",
    "    video = tf.reshape(image, shape=[batch_size, LEFT_CONTEXT + seq_len, HEIGHT, WIDTH, CHANNELS])\n",
    "    with tf.variable_scope(scope, 'Vision', [image], reuse=reuse):\n",
    "        net = slim.convolution(video, num_outputs=64, kernel_size=[3,12,12], stride=[1,6,6], padding=\"VALID\")\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        aux1 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "        net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        aux2 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "        net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        aux3 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "        net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        # at this point the tensor 'net' is of shape batch_size x seq_len x ...\n",
    "        aux4 = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "        net = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 1024, activation_fn=tf.nn.relu)\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 512, activation_fn=tf.nn.relu)\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 256, activation_fn=tf.nn.relu)\n",
    "        net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 128, activation_fn=None)\n",
    "        return layer_norm(tf.nn.elu(net + aux1 + aux2 + aux3 + aux4)) # aux[1-4] are residual connections (shortcuts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def apply_vision_simple(image, keep_prob, batch_size, seq_len, scope=None, reuse=None):\n",
    "#     video = tf.reshape(image, shape=[batch_size, LEFT_CONTEXT + seq_len, HEIGHT, WIDTH, CHANNELS])\n",
    "#     with tf.variable_scope(scope, 'Vision', [image], reuse=reuse):\n",
    "# #         net = slim.convolution(video, num_outputs=64, kernel_size=[3,12,12], stride=[1,6,6], padding=\"VALID\")\n",
    "#         net = slim.convolution(video, num_outputs=24, kernel_size=[3,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         aux1 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "# #         net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "#         net = slim.convolution(net, num_outputs=36, kernel_size=[1,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         aux2 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "# #         net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "#         net = slim.convolution(net, num_outputs=48, kernel_size=[1,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         aux3 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "        \n",
    "# #         net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "#         net = slim.convolution(net, num_outputs=64, kernel_size=[1,3,3], stride=[1,1,1], padding=\"VALID\")\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         aux4 = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "\n",
    "# #         net = slim.convolution(net, num_outputs=64, kernel_size=[1,3,3], stride=[1,1,1], padding=\"VALID\")\n",
    "# #         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "# #         # at this point the tensor 'net' is of shape batch_size x seq_len x ...\n",
    "# #         aux5 = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 128, activation_fn=None)\n",
    "\n",
    "#         net = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 1024, activation_fn=tf.nn.relu)\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         net = slim.fully_connected(net, 512, activation_fn=tf.nn.relu)\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         net = slim.fully_connected(net, 256, activation_fn=tf.nn.relu)\n",
    "#         net = tf.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "#         net = slim.fully_connected(net, 128, activation_fn=None)\n",
    "#         return layer_norm(tf.nn.elu(net + aux1 + aux2 + aux3 + aux4))# + aux5)) # aux[1-5] are residual connections (shortcuts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SamplingRNNCell(tf.contrib.rnn.RNNCell):\n",
    "    \"\"\"Simple sampling RNN cell.\"\"\"\n",
    "\n",
    "    def __init__(self, num_outputs, use_ground_truth, internal_cell):\n",
    "        \"\"\"\n",
    "        if use_ground_truth then don't sample\n",
    "        \"\"\"\n",
    "        self._num_outputs = num_outputs\n",
    "        self._use_ground_truth = use_ground_truth # boolean\n",
    "        self._internal_cell = internal_cell # may be LSTM or GRU or anything\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_outputs, self._internal_cell.state_size # previous output and bottleneck state\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_outputs # steering angle\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        (visual_feats, current_ground_truth) = inputs\n",
    "        prev_output, prev_state_internal = state\n",
    "        context = tf.concat([prev_output, visual_feats], 1)\n",
    "        new_output_internal, new_state_internal = internal_cell(context, prev_state_internal) # here the internal cell (e.g. LSTM) is called\n",
    "        new_output = tf.contrib.layers.fully_connected(\n",
    "            inputs=tf.concat([new_output_internal, prev_output, visual_feats], 1),\n",
    "            num_outputs=self._num_outputs,\n",
    "            activation_fn=None,\n",
    "            scope=\"OutputProjection\")\n",
    "        # if self._use_ground_truth == True, we pass the ground truth as the state; otherwise, we use the model's predictions\n",
    "        return new_output, (current_ground_truth if self._use_ground_truth else new_output, new_state_internal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTRUCT THE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vision/Conv/weights:0', 'Vision/Conv/biases:0', 'Vision/fully_connected/weights:0', 'Vision/fully_connected/biases:0', 'Vision/Conv_1/weights:0', 'Vision/Conv_1/biases:0', 'Vision/fully_connected_1/weights:0', 'Vision/fully_connected_1/biases:0', 'Vision/Conv_2/weights:0', 'Vision/Conv_2/biases:0', 'Vision/fully_connected_2/weights:0', 'Vision/fully_connected_2/biases:0', 'Vision/Conv_3/weights:0', 'Vision/Conv_3/biases:0', 'Vision/fully_connected_3/weights:0', 'Vision/fully_connected_3/biases:0', 'Vision/fully_connected_4/weights:0', 'Vision/fully_connected_4/biases:0', 'Vision/fully_connected_5/weights:0', 'Vision/fully_connected_5/biases:0', 'Vision/fully_connected_6/weights:0', 'Vision/fully_connected_6/biases:0', 'Vision/fully_connected_7/weights:0', 'Vision/fully_connected_7/biases:0', 'Vision/LayerNorm/beta:0', 'Vision/LayerNorm/gamma:0', 'controller_initial_state_0:0', 'controller_initial_state_1:0', 'controller_initial_state_2:0', 'predictor/rnn/lstm_cell/weights:0', 'predictor/rnn/lstm_cell/biases:0', 'predictor/rnn/lstm_cell/projection/weights:0', 'predictor/rnn/OutputProjection/weights:0', 'predictor/rnn/OutputProjection/biases:0']\n",
      "INFO:tensorflow:Summary name MAIN TRAIN METRIC: rmse_autoregressive_steering is illegal; using MAIN_TRAIN_METRIC__rmse_autoregressive_steering instead.\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # inputs  \n",
    "    learning_rate = tf.placeholder_with_default(input=1e-4, shape=())\n",
    "    keep_prob = tf.placeholder_with_default(input=1.0, shape=())\n",
    "    aux_cost_weight = tf.placeholder_with_default(input=0.1, shape=())\n",
    "    \n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE,LEFT_CONTEXT+SEQ_LEN), dtype=tf.string) # paths to png files\n",
    "    targets = tf.placeholder(shape=(BATCH_SIZE,SEQ_LEN,OUTPUT_DIM), dtype=tf.float32) # seq_len x batch_size x OUTPUT_DIM\n",
    "    targets_normalized = (targets - mean) / std\n",
    "    \n",
    "    input_images = tf.stack([tf.image.decode_png(tf.read_file(x)) # set dtype=tf.float32\n",
    "                            for x in tf.unstack(tf.reshape(inputs, shape=[(LEFT_CONTEXT+SEQ_LEN) * BATCH_SIZE]))])\n",
    "    input_images = -1.0 + 2.0 * tf.cast(input_images, tf.float32) / 255.0\n",
    "    input_images.set_shape([(LEFT_CONTEXT+SEQ_LEN) * BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\n",
    "    visual_conditions_reshaped = apply_vision_simple(image=input_images, keep_prob=keep_prob, \n",
    "                                                     batch_size=BATCH_SIZE, seq_len=SEQ_LEN)\n",
    "    visual_conditions = tf.reshape(visual_conditions_reshaped, [BATCH_SIZE, SEQ_LEN, -1])\n",
    "    visual_conditions = tf.nn.dropout(x=visual_conditions, keep_prob=keep_prob)\n",
    "    \n",
    "    rnn_inputs_with_ground_truth = (visual_conditions, targets_normalized)\n",
    "    rnn_inputs_autoregressive = (visual_conditions, tf.zeros(shape=(BATCH_SIZE, SEQ_LEN, OUTPUT_DIM), dtype=tf.float32))\n",
    "    \n",
    "    internal_cell = tf.contrib.rnn.LSTMCell(num_units=RNN_SIZE, num_proj=RNN_PROJ)\n",
    "    cell_with_ground_truth = SamplingRNNCell(num_outputs=OUTPUT_DIM, use_ground_truth=True, internal_cell=internal_cell)\n",
    "    cell_autoregressive = SamplingRNNCell(num_outputs=OUTPUT_DIM, use_ground_truth=False, internal_cell=internal_cell)\n",
    "    \n",
    "    def get_initial_state(complex_state_tuple_sizes):\n",
    "        flat_sizes = nest.flatten(complex_state_tuple_sizes)\n",
    "        init_state_flat = [tf.tile(multiples=[BATCH_SIZE, 1], \n",
    "            input=tf.get_variable(\"controller_initial_state_%d\" % i, initializer=tf.zeros_initializer, shape=([1, s]), dtype=tf.float32))\n",
    "         for i,s in enumerate(flat_sizes)]\n",
    "        init_state = nest.pack_sequence_as(complex_state_tuple_sizes, init_state_flat)\n",
    "        return init_state\n",
    "    def deep_copy_initial_state(complex_state_tuple):\n",
    "        flat_state = nest.flatten(complex_state_tuple)\n",
    "        flat_copy = [tf.identity(s) for s in flat_state]\n",
    "        deep_copy = nest.pack_sequence_as(complex_state_tuple, flat_copy)\n",
    "        return deep_copy\n",
    "    \n",
    "    controller_initial_state_variables = get_initial_state(cell_autoregressive.state_size)\n",
    "    controller_initial_state_autoregressive = deep_copy_initial_state(controller_initial_state_variables)\n",
    "    controller_initial_state_gt = deep_copy_initial_state(controller_initial_state_variables)\n",
    "\n",
    "    with tf.variable_scope(\"predictor\"):\n",
    "        out_gt, controller_final_state_gt = tf.nn.dynamic_rnn(cell=cell_with_ground_truth, inputs=rnn_inputs_with_ground_truth, \n",
    "                          sequence_length=[SEQ_LEN]*BATCH_SIZE, initial_state=controller_initial_state_gt, dtype=tf.float32,\n",
    "                          swap_memory=True, time_major=False)\n",
    "    with tf.variable_scope(\"predictor\", reuse=True):\n",
    "        out_autoregressive, controller_final_state_autoregressive = tf.nn.dynamic_rnn(cell=cell_autoregressive, inputs=rnn_inputs_autoregressive, \n",
    "                          sequence_length=[SEQ_LEN]*BATCH_SIZE, initial_state=controller_initial_state_autoregressive, dtype=tf.float32,\n",
    "                          swap_memory=True, time_major=False)\n",
    "    \n",
    "    mse_gt = tf.reduce_mean(tf.squared_difference(out_gt, targets_normalized))\n",
    "    mse_autoregressive = tf.reduce_mean(tf.squared_difference(out_autoregressive, targets_normalized))\n",
    "    mse_autoregressive_steering = tf.reduce_mean(tf.squared_difference(out_autoregressive[:, :, 0], targets_normalized[:, :, 0]))\n",
    "    steering_predictions = (out_autoregressive[:, :, 0] * std[0]) + mean[0]\n",
    "    \n",
    "    total_loss = mse_autoregressive_steering + aux_cost_weight * (mse_gt + mse_autoregressive)\n",
    "    \n",
    "    optimizer = get_optimizer(total_loss, learning_rate)\n",
    "\n",
    "    tf.summary.scalar(\"MAIN TRAIN METRIC: rmse_autoregressive_steering\", tf.sqrt(mse_autoregressive_steering))\n",
    "    tf.summary.scalar(\"rmse_gt\", tf.sqrt(mse_gt))\n",
    "    tf.summary.scalar(\"rmse_autoregressive\", tf.sqrt(mse_autoregressive))\n",
    "    \n",
    "    summaries = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('ckpt/train_summary', graph=graph)\n",
    "    valid_writer = tf.summary.FileWriter('ckpt/valid_summary', graph=graph)\n",
    "    saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.getcwd() + \"/ckpt\"\n",
    "\n",
    "global_train_step = 0\n",
    "global_valid_step = 0\n",
    "\n",
    "KEEP_PROB_TRAIN = 0.25\n",
    "\n",
    "def do_epoch(session, sequences, mode):\n",
    "    global global_train_step, global_valid_step\n",
    "    test_predictions = {}\n",
    "    valid_predictions = {}\n",
    "    batch_generator = BatchGenerator(sequence=sequences, seq_len=SEQ_LEN, batch_size=BATCH_SIZE)\n",
    "    total_num_steps = int(1 + (batch_generator.indices[1] - 1) / SEQ_LEN)\n",
    "    controller_final_state_gt_cur, controller_final_state_autoregressive_cur = None, None\n",
    "    acc_loss = np.float128(0.0)\n",
    "    for step in range(total_num_steps):\n",
    "        feed_inputs, feed_targets = batch_generator.next()\n",
    "        feed_dict = {inputs : feed_inputs, targets : feed_targets}\n",
    "        if controller_final_state_autoregressive_cur is not None:\n",
    "            feed_dict.update({controller_initial_state_autoregressive : controller_final_state_autoregressive_cur})\n",
    "        if controller_final_state_gt_cur is not None:\n",
    "            feed_dict.update({controller_final_state_gt : controller_final_state_gt_cur})\n",
    "        if mode == \"train\":\n",
    "            feed_dict.update({keep_prob : KEEP_PROB_TRAIN})\n",
    "            summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            train_writer.add_summary(summary, global_train_step)\n",
    "            global_train_step += 1\n",
    "        elif mode == \"valid\":\n",
    "            model_predictions, summary, loss, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, summaries, mse_autoregressive_steering, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            valid_writer.add_summary(summary, global_valid_step)\n",
    "            global_valid_step += 1  \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            steering_targets = feed_targets[:, :, 0].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            stats = np.stack([steering_targets, model_predictions, (steering_targets - model_predictions)**2])\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                valid_predictions[img] = stats[:, i]\n",
    "        elif mode == \"test\":\n",
    "            model_predictions, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)           \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                test_predictions[img] = model_predictions[i]\n",
    "        if mode != \"test\":\n",
    "            acc_loss += loss\n",
    "            print('\\r', step + 1, \"/\", total_num_steps, np.sqrt(acc_loss / (step+1)))\n",
    "    print()\n",
    "    return (np.sqrt(acc_loss / total_num_steps), valid_predictions) if mode != \"test\" else (None, test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAUNCH THE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-59-a63f281a5da7>:5: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Starting epoch 0\n",
      "Validation:\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=2\n",
    "\n",
    "best_validation_score = None\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    print('Initialized')\n",
    "    ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if ckpt:\n",
    "        print(\"Restoring from\", ckpt)\n",
    "        saver.restore(sess=session, save_path=ckpt)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"Starting epoch %d\" % epoch)\n",
    "        print(\"Validation:\")\n",
    "        valid_score, valid_predictions = do_epoch(session=session, sequences=valid_seq, mode=\"valid\")\n",
    "        if best_validation_score is None: \n",
    "            best_validation_score = valid_score\n",
    "        if valid_score < best_validation_score:\n",
    "            saver.save(session, 'ckpt/checkpoint-TK')\n",
    "            best_validation_score = valid_score\n",
    "            print('\\r', \"SAVED at epoch %d\" % epoch)\n",
    "            with open(\"ckpt/valid-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                result = np.float128(0.0)\n",
    "                for img, stats in valid_predictions.items():\n",
    "                    print(img, stats, file=out)\n",
    "                    result += stats[-1]\n",
    "            print(\"Validation unnormalized RMSE:\", np.sqrt(result / len(valid_predictions)))\n",
    "            with open(\"ckpt/test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                _, test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                print(\"frame_id,steering_angle\", file=out)\n",
    "                \n",
    "                for img, pred in test_predictions.items():\n",
    "#                     img = img.replace(\"challenge_2/Test-final/center/\", \"\")\n",
    "                    print(\"%s,%f\" % (img, pred), file=out)\n",
    "        if epoch != NUM_EPOCHS - 1:\n",
    "            print(\"Training\")\n",
    "            do_epoch(session=session, sequences=train_seq, mode=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
